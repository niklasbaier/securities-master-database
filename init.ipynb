{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import config as cf\n",
    "import utils as ut\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---------------| Successfully connected to securities_master. |---------------|\n",
      "|---------------| Successfully connected to Alpaca API. |---------------|\n"
     ]
    }
   ],
   "source": [
    "# Connect to DB\n",
    "conn = ut.connect_db()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Connect to Alpaca API\n",
    "api = ut.connect_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write exchanges to SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchanges\n",
    "sql = \"\"\"\n",
    "  INSERT INTO exchange (mic_code, acronym, name, region, country, city, currency) VALUES \n",
    "  ('XNAS', 'NASDAQ', 'Nasdaq - All Markets', 'North America', 'United States', 'New York', 'USD'),\n",
    "  ('XNYS', 'NYSE', 'New York Stock Exchange', 'North America', 'United States', 'New York', 'USD'),\n",
    "  ('XASE', 'AMEX', 'NYSE American', 'North America', 'United States', 'New York', 'USD'),\n",
    "  ('ARCX', 'ARCA', 'NYSE Arca', 'North America', 'United States', 'New York', 'USD'),\n",
    "  ('BATS', 'BATS', 'Bats Global Markets', 'North America', 'United States', 'Chicago', 'USD');\"\"\"\n",
    "cursor.execute(sql)\n",
    "conn.commit()\n",
    "print(\"|---------------| Data successfully written to database. |---------------|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write instruments to SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all assets\n",
    "assets = api.list_assets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchanges\n",
    "nasdaq = ut.populate_exchange_list('NASDAQ', assets) # 4707\n",
    "nyse = ut.populate_exchange_list('NYSE', assets) # 2955\n",
    "amex = ut.populate_exchange_list('AMEX', assets) # 263\n",
    "arca = ut.populate_exchange_list('ARCA', assets) # 1788\n",
    "bats = ut.populate_exchange_list('BATS', assets) # 531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast Tickers to YF-format\n",
    "nasdaq = sorted(ut.cast_to_yf(nasdaq))\n",
    "nyse = sorted(ut.cast_to_yf(nyse))\n",
    "amex = sorted(ut.cast_to_yf(amex))\n",
    "arca = sorted(ut.cast_to_yf(arca))\n",
    "bats = sorted(ut.cast_to_yf(bats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASDAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_alpaca = ut.populate_exchange_df('NASDAQ', assets, conn)\n",
    "nasdaq_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(nasdaq, cf.BATCH_SIZE)\n",
    "split_arr = np.array_split(nasdaq, splits)\n",
    "nasdaq_info = pd.DataFrame()\n",
    "\n",
    "count = 1\n",
    "for array in split_arr:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.get_corporate_info(array, 50, cf.KOI)\n",
    "  nasdaq_info = nasdaq_info.append(tmp)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ut.cast_to_alpaca(nasdaq_info['symbol'].tolist()) # cast tickers back to Alpaca-format\n",
    "nasdaq_info.drop('symbol', axis = 1, inplace = True)\n",
    "nasdaq_info.insert(0, 'ticker', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df = pd.merge(nasdaq_alpaca, nasdaq_info, on = 'ticker', how = 'outer')\n",
    "nasdaq_df = nasdaq_df.sort_values(by = ['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df.to_csv('data/NASDAQ.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_alpaca = ut.populate_exchange_df('NYSE', assets, conn)\n",
    "nyse_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(nyse, cf.BATCH_SIZE)\n",
    "split_arr = np.array_split(nyse, splits)\n",
    "nyse_info = pd.DataFrame()\n",
    "\n",
    "count = 1\n",
    "for array in split_arr:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.get_corporate_info(array, 50, cf.KOI)\n",
    "  nyse_info = nyse_info.append(tmp)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ut.cast_to_alpaca(nyse_info['symbol'].tolist())\n",
    "nyse_info.drop('symbol', axis = 1, inplace = True)\n",
    "nyse_info.insert(0, 'ticker', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_df = pd.merge(nyse_alpaca, nyse_info, on = 'ticker', how = 'outer')\n",
    "nyse_df = nyse_df.sort_values(by = ['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_df.to_csv('data/NYSE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_alpaca = ut.populate_exchange_df('AMEX', assets, conn)\n",
    "amex_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(amex, cf.BATCH_SIZE)\n",
    "split_arr = np.array_split(amex, splits)\n",
    "amex_info = pd.DataFrame()\n",
    "\n",
    "count = 1\n",
    "for array in split_arr:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.get_corporate_info(array, 50, cf.KOI)\n",
    "  amex_info = amex_info.append(tmp)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ut.cast_to_alpaca(amex_info['symbol'].tolist())\n",
    "amex_info.drop('symbol', axis = 1, inplace = True)\n",
    "amex_info.insert(0, 'ticker', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_df = pd.merge(amex_alpaca, amex_info, on = 'ticker', how = 'outer')\n",
    "amex_df = amex_df.sort_values(by = ['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_df.to_csv('data/AMEX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_alpaca = ut.populate_exchange_df('ARCA', assets, conn)\n",
    "arca_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(arca, cf.BATCH_SIZE)\n",
    "split_arr = np.array_split(arca, splits)\n",
    "arca_info = pd.DataFrame()\n",
    "\n",
    "count = 1\n",
    "for array in split_arr:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.get_corporate_info(array, 50, cf.KOI)\n",
    "  arca_info = arca_info.append(tmp)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ut.cast_to_alpaca(arca_info['symbol'].tolist())\n",
    "arca_info.drop('symbol', axis = 1, inplace = True)\n",
    "arca_info.insert(0, 'ticker', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_df = pd.merge(arca_alpaca, arca_info, on = 'ticker', how = 'outer')\n",
    "arca_df = arca_df.sort_values(by = ['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_df.to_csv('data/ARCA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_alpaca = ut.populate_exchange_df('BATS', assets, conn)\n",
    "bats_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(bats, cf.BATCH_SIZE)\n",
    "split_arr = np.array_split(bats, splits)\n",
    "bats_info = pd.DataFrame()\n",
    "\n",
    "count = 1\n",
    "for array in split_arr:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.get_corporate_info(array, 50, cf.KOI)\n",
    "  bats_info = bats_info.append(tmp)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ut.cast_to_alpaca(bats_info['symbol'].tolist())\n",
    "bats_info.drop('symbol', axis = 1, inplace = True)\n",
    "bats_info.insert(0, 'ticker', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_df = pd.merge(bats_alpaca, bats_info, on = 'ticker', how = 'outer')\n",
    "bats_df = bats_df.sort_values(by = ['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_df.to_csv('data/BATS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually write to SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df = pd.read_csv('data/NASDAQ.csv')\n",
    "nasdaq_df = nasdaq_df.loc[:, nasdaq_df.columns != 'Unnamed: 0']\n",
    "nasdaq_df = nasdaq_df.replace({np.nan: None}) # replace NaN with None for MySQL\n",
    "\n",
    "nyse_df = pd.read_csv('data/NYSE.csv')\n",
    "nyse_df = nyse_df.loc[:, nyse_df.columns != 'Unnamed: 0']\n",
    "nyse_df = nyse_df.replace({np.nan: None})\n",
    "\n",
    "amex_df = pd.read_csv('data/AMEX.csv')\n",
    "amex_df = amex_df.loc[:, amex_df.columns != 'Unnamed: 0']\n",
    "amex_df = amex_df.replace({np.nan: None})\n",
    "\n",
    "arca_df = pd.read_csv('data/ARCA.csv')\n",
    "arca_df = arca_df.loc[:, arca_df.columns != 'Unnamed: 0']\n",
    "arca_df = arca_df.replace({np.nan: None})\n",
    "\n",
    "bats_df = pd.read_csv('data/BATS.csv')\n",
    "bats_df = bats_df.loc[:, bats_df.columns != 'Unnamed: 0']\n",
    "bats_df = bats_df.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for easy iterating\n",
    "exchanges = {\n",
    "  'NASDAQ': nasdaq_df,\n",
    "  'NYSE': nyse_df,\n",
    "  'AMEX': amex_df,\n",
    "  'ARCA': arca_df,\n",
    "  'BATS': bats_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to the database\n",
    "for key, exchange in exchanges.items():\n",
    "  for row in exchange.itertuples(index = False):\n",
    "    cursor.execute(\"INSERT INTO instrument (exchange_id, ticker, name, sector, industry, country, website) VALUES (%s, %s, %s, %s, %s, %s, %s)\", row)\n",
    "conn.commit()\n",
    "print(\"|---------------| Data successfully written to database. |---------------|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write vendors to SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo Finance\n",
    "sql = \"INSERT INTO vendor (name, website) VALUES ('Yahoo Finance', 'https://finance.yahoo.com/')\"\n",
    "cursor.execute(sql)\n",
    "conn.commit()\n",
    "print(\"|---------------| Data successfully written to database. |---------------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca\n",
    "sql = \"INSERT INTO vendor (name, website) VALUES ('Alpaca', 'https://alpaca.markets/')\"\n",
    "cursor.execute(sql)\n",
    "conn.commit()\n",
    "print(\"|---------------| Data successfully written to database. |---------------|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write prices to SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "yesterday = str(today - datetime.timedelta(days = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_tickers = ut.get_exchange_tickers('NASDAQ', conn)\n",
    "nyse_tickers = ut.get_exchange_tickers('NYSE', conn)\n",
    "amex_tickers = ut.get_exchange_tickers('AMEX', conn)\n",
    "arca_tickers = ut.get_exchange_tickers('ARCA', conn)\n",
    "bats_tickers = ut.get_exchange_tickers('BATS', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASDAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(nasdaq_tickers['ticker'].to_list(), cf.BATCH_SIZE)\n",
    "nasdaq_tickers_list = [nasdaq_tickers.loc[i : i + cf.BATCH_SIZE - 1, : ] for i in range(0, len(nasdaq_tickers), cf.BATCH_SIZE)]\n",
    "nasdaq_excepts = []\n",
    "\n",
    "count = 1\n",
    "for batch in nasdaq_tickers_list:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.write_historical_prices_yf(batch, conn, cursor, None, yesterday)\n",
    "  nasdaq_excepts.append(tmp)\n",
    "  count += 1\n",
    "\n",
    "pickle.dump(ut.flatten_exceptions(nasdaq_excepts), open(\"data/NASDAQ.txt\", \"wb\")) # save exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_excepts = pickle.load(open(\"data/NASDAQ.txt\", \"rb\"))\n",
    "nasdaq_excepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_alpaca = pd.DataFrame()\n",
    "for ticker in nasdaq_excepts:\n",
    "  nasdaq_alpaca = nasdaq_alpaca.append(nasdaq_tickers[nasdaq_tickers['ticker'] == ticker])\n",
    "ut.write_historical_prices_alpaca(nasdaq_alpaca, api, conn, cursor, None, yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(nyse_tickers['ticker'].to_list(), cf.BATCH_SIZE)\n",
    "nyse_tickers_list = [nyse_tickers.loc[i : i + cf.BATCH_SIZE - 1, : ] for i in range(0, len(nyse_tickers), cf.BATCH_SIZE)]\n",
    "nyse_excepts = []\n",
    "\n",
    "count = 1\n",
    "for batch in nyse_tickers_list:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.write_historical_prices_yf(batch, conn, cursor, None, yesterday)\n",
    "  nyse_excepts.append(tmp)\n",
    "  count += 1\n",
    "\n",
    "pickle.dump(ut.flatten_exceptions(nyse_excepts), open(\"data/NYSE.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_excepts = pickle.load(open(\"data/NYSE.txt\", \"rb\"))\n",
    "nyse_excepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_alpaca = pd.DataFrame()\n",
    "for ticker in nyse_excepts:\n",
    "  nyse_alpaca = nyse_alpaca.append(nyse_tickers[nyse_tickers['ticker'] == ticker])\n",
    "ut.write_historical_prices_alpaca(nyse_alpaca, api, conn, cursor, None, yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(amex_tickers['ticker'].to_list(), cf.BATCH_SIZE)\n",
    "amex_tickers_list = [amex_tickers.loc[i : i + cf.BATCH_SIZE - 1, : ] for i in range(0, len(amex_tickers), cf.BATCH_SIZE)]\n",
    "amex_excepts = []\n",
    "\n",
    "count = 1\n",
    "for batch in amex_tickers_list:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.write_historical_prices_yf(batch, conn, cursor, None, yesterday)\n",
    "  amex_excepts.append(tmp)\n",
    "  count += 1\n",
    "\n",
    "pickle.dump(ut.flatten_exceptions(amex_excepts), open(\"data/AMEX.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_excepts = pickle.load(open(\"data/AMEX.txt\", \"rb\"))\n",
    "amex_excepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_alpaca = pd.DataFrame()\n",
    "for ticker in amex_excepts:\n",
    "  amex_alpaca = amex_alpaca.append(amex_tickers[amex_tickers['ticker'] == ticker])\n",
    "ut.write_historical_prices_alpaca(amex_alpaca, api, conn, cursor, None, yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(arca_tickers['ticker'].to_list(), cf.BATCH_SIZE)\n",
    "arca_tickers_list = [arca_tickers.loc[i : i + cf.BATCH_SIZE - 1, : ] for i in range(0, len(arca_tickers), cf.BATCH_SIZE)]\n",
    "arca_excepts = []\n",
    "\n",
    "count = 1\n",
    "for batch in arca_tickers_list:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.write_historical_prices_yf(batch, conn, cursor, None, yesterday)\n",
    "  arca_excepts.append(tmp)\n",
    "  count += 1\n",
    "\n",
    "pickle.dump(ut.flatten_exceptions(arca_excepts), open(\"data/ARCA.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_excepts = pickle.load(open(\"data/ARCA.txt\", \"rb\"))\n",
    "arca_excepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arca_alpaca = pd.DataFrame()\n",
    "for ticker in arca_excepts:\n",
    "  arca_alpaca = arca_alpaca.append(arca_tickers[arca_tickers['ticker'] == ticker])\n",
    "ut.write_historical_prices_alpaca(arca_alpaca, api, conn, cursor, None, yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ut.determine_splits(bats_tickers['ticker'].to_list(), cf.BATCH_SIZE)\n",
    "bats_tickers_list = [bats_tickers.loc[i : i + cf.BATCH_SIZE - 1, : ] for i in range(0, len(bats_tickers), cf.BATCH_SIZE)]\n",
    "bats_excepts = []\n",
    "\n",
    "count = 1\n",
    "for batch in bats_tickers_list:\n",
    "  print(\"|---------------| Split {} of {} |---------------|\".format(count, splits))\n",
    "  tmp = ut.write_historical_prices_yf(batch, conn, cursor, None, yesterday)\n",
    "  bats_excepts.append(tmp)\n",
    "  count += 1\n",
    "\n",
    "pickle.dump(ut.flatten_exceptions(bats_excepts), open(\"data/BATS.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_excepts = pickle.load(open(\"data/BATS.txt\", \"rb\"))\n",
    "bats_excepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_alpaca = pd.DataFrame()\n",
    "for ticker in bats_excepts:\n",
    "  bats_alpaca = bats_alpaca.append(bats_tickers[bats_tickers['ticker'] == ticker])\n",
    "ut.write_historical_prices_alpaca(bats_alpaca, api, conn, cursor, None, yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write industries to SMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS `industry` (\n",
    "  `id` INT(11) NOT NULL AUTO_INCREMENT,\n",
    "  `name` VARCHAR(255) NULL,\n",
    "  `created_date` DATETIME NULL DEFAULT CURRENT_TIMESTAMP(),\n",
    "  `last_updated` DATETIME NULL DEFAULT CURRENT_TIMESTAMP() ON UPDATE CURRENT_TIMESTAMP(),\n",
    "  PRIMARY KEY (`id`))\n",
    "  ENGINE = InnoDB\n",
    "  DEFAULT CHARACTER SET = utf8;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Advertising Agencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Agricultural Inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Airports &amp; Air Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Utilities—Regulated Electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Utilities—Regulated Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Utilities—Regulated Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Utilities—Renewable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Waste Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         industry\n",
       "27           Advertising Agencies\n",
       "73            Aerospace & Defense\n",
       "77            Agricultural Inputs\n",
       "3                        Airlines\n",
       "9         Airports & Air Services\n",
       "..                            ...\n",
       "30   Utilities—Regulated Electric\n",
       "131       Utilities—Regulated Gas\n",
       "68      Utilities—Regulated Water\n",
       "24            Utilities—Renewable\n",
       "61               Waste Management\n",
       "\n",
       "[151 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industries = pd.read_sql(\"SELECT DISTINCT(industry) FROM instrument;\", conn)\n",
    "industries.dropna(inplace = True)\n",
    "industries.sort_values(by = 'industry', inplace = True)\n",
    "industries = industries.iloc[1:]\n",
    "industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in industries.itertuples(index = False):\n",
    "  cursor.execute(\"INSERT INTO industry (name) VALUES (%s)\", row)\n",
    "conn.commit()\n",
    "print(\"|---------------| Data successfully written to database. |---------------|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write industry_returns to SMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS `industry_return` (\n",
    "  `id` INT(11) NOT NULL AUTO_INCREMENT,\n",
    "  `industry_id` INT(11) NOT NULL,\n",
    "  `return_date` DATE NOT NULL,\n",
    "  `simple_return` DECIMAL(11,6) NULL DEFAULT NULL,\n",
    "  `created_date` DATETIME NULL DEFAULT CURRENT_TIMESTAMP(),\n",
    "  `last_updated` DATETIME NULL DEFAULT CURRENT_TIMESTAMP() ON UPDATE CURRENT_TIMESTAMP(),\n",
    "  PRIMARY KEY (`id`),\n",
    "  INDEX `return_date` (`return_date` ASC),\n",
    "  INDEX `industry_id` (`industry_id` ASC),\n",
    "  CONSTRAINT `fk_industry_id`\n",
    "    FOREIGN KEY (`industry_id`)\n",
    "    REFERENCES `industry` (`id`)\n",
    "    ON DELETE NO ACTION\n",
    "    ON UPDATE NO ACTION)\n",
    "  ENGINE = InnoDB\n",
    "  DEFAULT CHARACTER SET = utf8;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Advertising Agencies',\n",
       " 'Aerospace & Defense',\n",
       " 'Agricultural Inputs',\n",
       " 'Airlines',\n",
       " 'Airports & Air Services',\n",
       " 'Aluminum',\n",
       " 'Apparel Manufacturing',\n",
       " 'Apparel Retail',\n",
       " 'Asset Management',\n",
       " 'Auto & Truck Dealerships',\n",
       " 'Auto Manufacturers',\n",
       " 'Auto Parts',\n",
       " 'Banks—Diversified',\n",
       " 'Banks—Regional',\n",
       " 'Beverages—Brewers',\n",
       " 'Beverages—Non-Alcoholic',\n",
       " 'Beverages—Wineries & Distilleries',\n",
       " 'Biotechnology',\n",
       " 'Broadcasting',\n",
       " 'Building Materials',\n",
       " 'Building Products & Equipment',\n",
       " 'Business Equipment & Supplies',\n",
       " 'Capital Markets',\n",
       " 'Chemicals',\n",
       " 'Closed-End Fund - Equity',\n",
       " 'Closed-End Fund - Foreign',\n",
       " 'Coking Coal',\n",
       " 'Communication Equipment',\n",
       " 'Computer Hardware',\n",
       " 'Confectioners',\n",
       " 'Conglomerates',\n",
       " 'Consulting Services',\n",
       " 'Consumer Electronics',\n",
       " 'Copper',\n",
       " 'Credit Services',\n",
       " 'Department Stores',\n",
       " 'Diagnostics & Research',\n",
       " 'Discount Stores',\n",
       " 'Drug Manufacturers—General',\n",
       " 'Drug Manufacturers—Specialty & Generic',\n",
       " 'Education & Training Services',\n",
       " 'Electrical Equipment & Parts',\n",
       " 'Electronic Components',\n",
       " 'Electronic Gaming & Multimedia',\n",
       " 'Electronics & Computer Distribution',\n",
       " 'Engineering & Construction',\n",
       " 'Entertainment',\n",
       " 'Farm & Heavy Construction Machinery',\n",
       " 'Farm Products',\n",
       " 'Financial Conglomerates',\n",
       " 'Financial Data & Stock Exchanges',\n",
       " 'Food Distribution',\n",
       " 'Footwear & Accessories',\n",
       " 'Furnishings, Fixtures & Appliances',\n",
       " 'Gambling',\n",
       " 'Gold',\n",
       " 'Grocery Stores',\n",
       " 'Health Information Services',\n",
       " 'Healthcare Plans',\n",
       " 'Home Improvement Retail',\n",
       " 'Household & Personal Products',\n",
       " 'Industrial Distribution',\n",
       " 'Information Technology Services',\n",
       " 'Infrastructure Operations',\n",
       " 'Insurance Brokers',\n",
       " 'Insurance—Diversified',\n",
       " 'Insurance—Life',\n",
       " 'Insurance—Property & Casualty',\n",
       " 'Insurance—Reinsurance',\n",
       " 'Insurance—Specialty',\n",
       " 'Integrated Freight & Logistics',\n",
       " 'Internet Content & Information',\n",
       " 'Internet Information Providers',\n",
       " 'Internet Retail',\n",
       " 'Leisure',\n",
       " 'Lodging',\n",
       " 'Lumber & Wood Production',\n",
       " 'Luxury Goods',\n",
       " 'Marine Shipping',\n",
       " 'Medical Appliances & Equipment',\n",
       " 'Medical Care Facilities',\n",
       " 'Medical Devices',\n",
       " 'Medical Distribution',\n",
       " 'Medical Instruments & Supplies',\n",
       " 'Metal Fabrication',\n",
       " 'Money Center Banks',\n",
       " 'Mortgage Finance',\n",
       " 'Oil & Gas Drilling',\n",
       " 'Oil & Gas E&P',\n",
       " 'Oil & Gas Equipment & Services',\n",
       " 'Oil & Gas Integrated',\n",
       " 'Oil & Gas Midstream',\n",
       " 'Oil & Gas Refining & Marketing',\n",
       " 'Other Industrial Metals & Mining',\n",
       " 'Other Precious Metals & Mining',\n",
       " 'Packaged Foods',\n",
       " 'Packaging & Containers',\n",
       " 'Paper & Paper Products',\n",
       " 'Personal Services',\n",
       " 'Pharmaceutical Retailers',\n",
       " 'Pollution & Treatment Controls',\n",
       " 'Publishing',\n",
       " 'REIT—Diversified',\n",
       " 'REIT—Healthcare Facilities',\n",
       " 'REIT—Hotel & Motel',\n",
       " 'REIT—Industrial',\n",
       " 'REIT—Mortgage',\n",
       " 'REIT—Office',\n",
       " 'REIT—Residential',\n",
       " 'REIT—Retail',\n",
       " 'REIT—Specialty',\n",
       " 'Railroads',\n",
       " 'Real Estate Services',\n",
       " 'Real Estate—Development',\n",
       " 'Real Estate—Diversified',\n",
       " 'Recreational Vehicles',\n",
       " 'Rental & Leasing Services',\n",
       " 'Residential Construction',\n",
       " 'Resorts & Casinos',\n",
       " 'Restaurants',\n",
       " 'Scientific & Technical Instruments',\n",
       " 'Security & Protection Services',\n",
       " 'Security Software & Services',\n",
       " 'Semiconductor Equipment & Materials',\n",
       " 'Semiconductors',\n",
       " 'Shell Companies',\n",
       " 'Silver',\n",
       " 'Software—Application',\n",
       " 'Software—Infrastructure',\n",
       " 'Solar',\n",
       " 'Specialty Business Services',\n",
       " 'Specialty Chemicals',\n",
       " 'Specialty Industrial Machinery',\n",
       " 'Specialty Retail',\n",
       " 'Staffing & Employment Services',\n",
       " 'Steel',\n",
       " 'Telecom Services',\n",
       " 'Textile Manufacturing',\n",
       " 'Thermal Coal',\n",
       " 'Tobacco',\n",
       " 'Tools & Accessories',\n",
       " 'Travel Services',\n",
       " 'Trucking',\n",
       " 'Uranium',\n",
       " 'Utilities—Diversified',\n",
       " 'Utilities—Independent Power Producers',\n",
       " 'Utilities—Regulated Electric',\n",
       " 'Utilities—Regulated Gas',\n",
       " 'Utilities—Regulated Water',\n",
       " 'Utilities—Renewable',\n",
       " 'Waste Management']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industries = pd.read_sql(\"SELECT DISTINCT(name) FROM industry;\", conn)\n",
    "industries = list(industries.name)\n",
    "industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---------------| Data successfully written to database. |---------------|\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "for industry in industries:\n",
    "  industry_df = pd.DataFrame()\n",
    "  sql = \"\"\"\n",
    "    SELECT ins.id, p.price_date, p.adj_close_price\n",
    "    FROM instrument AS ins\n",
    "    INNER JOIN price AS p\n",
    "    ON ins.id = p.ticker_id\n",
    "    WHERE industry = '{}';\"\"\".format(industry)\n",
    "\n",
    "  tmp = pd.read_sql(sql, conn)\n",
    "  tmp['simple_return'] = tmp.adj_close_price.pct_change()\n",
    "\n",
    "  for i in range(1, len(tmp.id)):\n",
    "    if tmp.id.at[i] != tmp.id.at[i-1]:\n",
    "      tmp.simple_return.at[i] = None\n",
    "\n",
    "  industry_df = tmp.groupby('price_date').mean().iloc[:,-1].to_frame()\n",
    "  industry_df[\"price_date\"] = industry_df.index\n",
    "  industry_df.reset_index(drop = True, inplace = True)\n",
    "  industry_df['id'] = count\n",
    "  industry_df = industry_df.reindex(columns = ['id', 'price_date', 'simple_return'])\n",
    "  industry_df.replace({np.nan: None}, inplace = True)\n",
    "\n",
    "  for row in industry_df.itertuples(index = False):\n",
    "    cursor.execute(\"INSERT INTO industry_return (industry_id, return_date, simple_return) VALUES (%s, %s, %s)\", row)\n",
    "\n",
    "  count += 1\n",
    "\n",
    "conn.commit()\n",
    "print(\"|---------------| Data successfully written to database. |---------------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_date</th>\n",
       "      <th>simple_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>-0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>0.017334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-07</td>\n",
       "      <td>-0.022726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-08</td>\n",
       "      <td>-0.034881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>0.010945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>0.007821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>0.043127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>-0.016508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      return_date  simple_return\n",
       "0      1980-01-02            NaN\n",
       "1      1980-01-03      -0.005741\n",
       "2      1980-01-04       0.017334\n",
       "3      1980-01-07      -0.022726\n",
       "4      1980-01-08      -0.034881\n",
       "...           ...            ...\n",
       "10660  2022-04-11       0.010945\n",
       "10661  2022-04-12       0.007821\n",
       "10662  2022-04-13       0.043127\n",
       "10663  2022-04-14       0.001510\n",
       "10664  2022-04-18      -0.016508\n",
       "\n",
       "[10665 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_returns = pd.DataFrame()\n",
    "\n",
    "# for i in range(1, len(industries) + 1):\n",
    "for i in range(1, 5):\n",
    "  tmp = pd.read_sql(\"SELECT return_date, simple_return FROM industry_return WHERE industry_id = {}\".format(i), conn)\n",
    "  # industry_returns = pd.concat([industry_returns, tmp], axis = 1)\n",
    "\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>industry_id</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "      <th>151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>return_date</th>\n",
       "      <td>1980-03-17</td>\n",
       "      <td>1980-03-18</td>\n",
       "      <td>1980-03-19</td>\n",
       "      <td>1980-03-20</td>\n",
       "      <td>1980-03-21</td>\n",
       "      <td>1980-03-24</td>\n",
       "      <td>1980-03-25</td>\n",
       "      <td>1980-03-26</td>\n",
       "      <td>1980-03-27</td>\n",
       "      <td>1980-03-28</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>2022-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_return</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005419</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>-0.003401</td>\n",
       "      <td>-0.029438</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>-0.014908</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>-0.004773</td>\n",
       "      <td>-0.016316</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>-0.005986</td>\n",
       "      <td>-0.003661</td>\n",
       "      <td>-0.018964</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>-0.007429</td>\n",
       "      <td>-0.00739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1662432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "industry_id           1           1           1           1           1    \\\n",
       "return_date    1980-03-17  1980-03-18  1980-03-19  1980-03-20  1980-03-21   \n",
       "simple_return         NaN   -0.005419    0.005889    0.004547   -0.003401   \n",
       "\n",
       "industry_id           1           1           1           1           1    \\\n",
       "return_date    1980-03-24  1980-03-25  1980-03-26  1980-03-27  1980-03-28   \n",
       "simple_return   -0.029438   -0.003509    0.011333   -0.014908     0.00712   \n",
       "\n",
       "industry_id    ...         151         151         151         151  \\\n",
       "return_date    ...  2022-04-04  2022-04-05  2022-04-06  2022-04-07   \n",
       "simple_return  ...   -0.002236   -0.004773   -0.016316    0.006289   \n",
       "\n",
       "industry_id           151         151         151         151         151  \\\n",
       "return_date    2022-04-08  2022-04-11  2022-04-12  2022-04-13  2022-04-14   \n",
       "simple_return   -0.005986   -0.003661   -0.018964    0.010144   -0.007429   \n",
       "\n",
       "industry_id           151  \n",
       "return_date    2022-04-18  \n",
       "simple_return    -0.00739  \n",
       "\n",
       "[2 rows x 1662432 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.set_index('industry_id').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9df93e7c5b32aa01e4b0cb4b10cdde717c610396fc96290c488abb3ee4ca8915"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('alpha-intelligence': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
